\section{Conclusion \& future directions}
\label{sec:conclude}
%{\em\color{gray} Need pargarph that resume what was presented}

As autonomous agents become more and more flexible it becomes difficult
to deal with all the possible changes that occur during the
mission. While there has been already work around the topic of robust
plan execution they always have been focused on threats coming from
execution feedback while not considering how the potential emergence of
new goals could impact how the current plan should be executed. In this
paper we discussed this aspect and proposed a solution that relies on
extra information on the urgency of an objective. By propagating this
through the plan structure we were able to leverage this information for
supporting the plan executive decision starting actions proactively or
not. A second algorithm allowed to propagate this information during the
planning phase ensuring that the executive can identify this information
quickly.

\fcomment{This is just a quick presentation on potential future
  direction} As we stated in the related works our approach do not
really address dynamic controllability and have the more classic
assumption present in many planning frameworks that time-points are
controllable. A side effect of this is that in its current state it may
result on the system to decide to defer action as late as possible. In
our example, this would result on the agent leaving the Grocery as late
as 19:30 making the rest of its plan brittle to any delay due for
example to traffic jam on its way back. This need to be further
addressed in the future and especially how our work can be integrated
with work presented in \cite{morris01}.

Further as of today we consider that the qualification of the goal is
predefined when the goal is submitted by the planner. It is possible
though that part of this can be refined on some cases based on the
nature of the goal. Looking back at our domain, one can note that the 2
goals provided are constrained differently on their start time; while
{\em Have an apple} start time is limited only on its upper bound, the
being back at home conversely is constrained only on the lower bound of
its start time. This difference hints on some of the issues we
presented. While we do consider that explicit information of tese goals
help the plan execution to be improved when such information is not
initially present. We also are aware that the nature of the constraints
within the goal itself can help identify the best policy to be done. It
is obvious that has have an apple have a deadline it is better to be
proactive on the actions that contribute to this goal. Conversely, the
other goal only matter if it appears fairly late in the plan which mena
that it is probably better to not start to complete this [part of the
plan too aggressively. We plan to further explore how we can refine the
distinction between the different policies by using the information
provided by the constraints of the different objectives.
 
%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "aaai13"
%%% End: 
