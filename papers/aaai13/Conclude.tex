\section{Conclusion \& future directions}
\label{sec:conclude}
%{\em\color{gray} Need pargarph that resume what was presented}

As autonomous agents become more and more flexible it becomes difficult
to deal with all the possible changes that occur during the
mission. While there has already been work around the topic of robust
plan execution, they always have been focused on threats coming from
execution feedback while not considering how the potential emergence of
new goals could impact how the current plan should be executed. In this
paper, we discussed this aspect and proposed a solution that relies on
extra information on the urgency of an objective. By propagating this
through the plan structure, we were able to leverage this information for
supporting the plan executive decision starting actions proactively or
not. A second algorithm allowed to propagate this information during the
planning phase ensuring that the executive can identify this information
quickly.

\fcomment{This is just a quick presentation on potential future
  direction} As we stated in the related works our approach does not
really address dynamic controllability and has the more classic
assumption present in many planning frameworks that time-points are
controllable. A side effect of this is that in its current state it may
result on the system to decide to defer action as late as possible. In
our example, this would result on the AUV leaving Vent1 as late
as 19:00 making the rest of its plan brittle to any delay due for
example to downward water currents on its way to the surface. This needs to be further
addressed in the future and, especially, how our work can be integrated
with work presented in \cite{morris01}.

Further as of today, we consider that the qualification of the goal is
predefined when the goal is submitted by the planner. It is possible
though that part of this can be refined on some cases based on the
nature of the goal. Looking back at our domain, one can note that the 2
goals provided are constrained differently on their start time; while
{\em Sample Vent2} start time is limited only on its upper bound, the
returning to surface conversely is constrained only on the lower bound of
its start time. This difference hints on some of the issues we
presented. While we do consider that explicit information of these goals
help the plan execution to be improved when such information is not
initially present. We also are aware that the nature of the constraints
within the goal itself can help identify the best policy to be done. It
is obvious that for Sampling Vent2 it is better to be
proactive on the actions that contribute to this goal. Conversely, the
other goal only matter if it appears fairly late in the plan which means
that it is probably better to not start completing this part of the
plan too aggressively. We plan to further explore how we can refine the
distinction between the different policies by using the information
provided by the constraints of the different objectives.
 
%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "aaai13"
%%% End: 
