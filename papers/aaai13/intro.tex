\section{Introduction}
\label{sec:intro}

As autonomous robots become more robust and persistent the likelihood
of their receiving new or modified objectives for tasking, during an
ongoing mission is high. Generative planning integrated within the
robotic architecture to fulfill current or such evolving agent
objectives and to deal with unanticipated situations is one approach
to enhance persistence while dealing with robot adaptation.  Earlier
work
\cite{AmbrosIngerson88,Haigh98,alami:1998p820,mus98,chien99,mus04,py10}
have contributed control architectures which embed planning engines
many of which support a rich representation dealing with durative
actions while ensuring partial plans are flexible for robust execution
\cite{lemai-chenevier2004}.

% such as \texttt{IPEM} \cite{AmbrosIngerson88}, \texttt{ROGUE}
% \cite{Haigh98}, and the LAAS architecture \cite{alami:1998p820} have
% all contributed to this field of research. Results from such work have
% lead to goal directed architectures that have sucessfully worked in
% the real-world such as the Remote Agent Experiment \cite{mus98}, the
% Autonomous Spacecraft Experiment \cite{chien99} and more recently the
% Teleo Reactive Executive \cite{py10}. Often these architectures embed
% planning engines that support a rich representation dealing with
% durative actions and resources while ensuring partial plans are
% flexible for robust execution \cite{lemai04}.  % A resulting consequence
% has been results in efficient approaches to temporal plan dispatch to
% ensure robust and sound execution \cite{mus98a,morris01}. 

While these approaches have been necessary to correctly execute a
\emph{flexible temporal plan}, they view the agent itself as
synchronously fulfilling goals provided a priori, without the
introduction of new goals which could alter mission state and
execution.
% This oversight is understandable as such goals are by nature unknown
% and therefore impossible to integrate within the plan limiting the
% ability to formally take them into account.
The natural choice was to make the agent execute its actions as early
as the temporal plan and the current context would allow, with the
assumption that, the robot would finish its plan as early as possible
providing more 'temporal' room for potential future objectives.  This
can be problematic when new objectives are added during the course of
mission execution and especially pronounced with persistent
robots. For instance, the agent may prematurely task the robot to
leave an area of exploration (and exploitation) before an oncoming new
objective for this same geographical area is received resulting in the
robot inefficiently having to return to a location that it has already
visited. Conversely, the robot waiting inordinately could waste time
with consequent lack of flexibility for coping with diverse execution
scenarios. In this context, it is important for the agent to make a
distinction between actions that can be taken proactively versus other
actions that may not be urgent.

The novelty of our work is twofold. First, we allow the agent to make
such a distinction \emph{during} execution, for each action, by
tracking causal relationships between goals. Second, while the
approach is simple yet elegant, it is motivated by our real-world
domain in the context of a continuously planning and executing robotic
explorer with focus on execution rather than plan synthesis.

% This
% allows us to determine an appropriate dispatch strategy for execution,
% based on the nature of the goals this action contributes to. While our
% approach manipulates the plan structure, it focuses on plan execution
% within the agent rather than plan synthesis.  For the purposes of this
% paper, we consider planning in abstraction while providing an
% anticipatory approach to continuous robotic plan execution.

The structure of this paper is as follows. We motivate with a
scenario illustrating the problem of flexible plan execution, discuss
previous efforts with robotic controllers for planning and dispatching
for execution. We then present the algorithmic detail to enable the
agent to decide at execution time when previously planned actions 
should be started. Finally, after presenting experimental results, 
we conclude and discuss potential directions for future research.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "aaai13"
%%% End: 
